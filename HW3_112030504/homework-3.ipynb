{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0MrEVoVmhOy"
      },
      "source": [
        "# Computer Vision Homework 3: Big vs Small Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hnrUlYrGWS"
      },
      "source": [
        "## Brief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_zuWZp5rSyN"
      },
      "source": [
        "Due date: Nov 13, 2023\n",
        "\n",
        "Required files: `homework-3.ipynb`, `report.pdf`\n",
        "\n",
        "To download the jupyter notebook from colab, you can refer to the colab tutorial we gave.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om7423NauKQ6"
      },
      "source": [
        "## Codes for Problem 1 and Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6pBqvV6RCq"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "73wanLwflUdb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "from torchvision import transforms, models, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtXEq_Yx5j-L"
      },
      "source": [
        "### Check GPU Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz3wOsYwmEz8",
        "outputId": "5ecc8f36-bb70-4630-d1fc-1d2f8314af83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbpaGDdwnX9g",
        "outputId": "c6147af7-0e96-4343-f9b8-4f425c780a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-6713d831-72d0-9681-f218-72d92a81c85a)\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAoPtdOR5ojk"
      },
      "source": [
        "### Set the Seed to Reproduce the Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wphy638XBNj-"
      },
      "outputs": [],
      "source": [
        "def set_all_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "set_all_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLmcH3NAH4wq"
      },
      "source": [
        "### Create Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VHp_O3_JgZE",
        "outputId": "9263a54f-7906-4a7a-cba6-a4543f6736cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 34320728.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2471, 0.2435, 0.2616)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=train_transform)\n",
        "valid_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "sixteenth_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//16)\n",
        "half_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//2)\n",
        "\n",
        "sixteenth_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sixteenth_train_sampler)\n",
        "half_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=half_train_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjFDtcWRnFS9"
      },
      "source": [
        "### Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgZV0CodnFS9",
        "outputId": "8fb7babf-5cff-40fa-c660-a0d8e125f5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 146MB/s]\n"
          ]
        }
      ],
      "source": [
        "# HINT: Remember to change the model to 'resnet50' and the weights to weights=\"IMAGENET1K_V1\" when needed.\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=\"IMAGENET1K_V1\")\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
        "num_fc = model.fc.in_features\n",
        "model.fc = nn.Linear(num_fc, 10)\n",
        "# Background: The original resnet18 is designed for ImageNet dataset to predict 1000 classes.\n",
        "# TODO: Change the output of the model to 10 class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZo50knhnFS_"
      },
      "source": [
        "### Training and Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXKJeYWnFTA",
        "outputId": "70e54346-0cb2-4b2b-a48d-42cd5f589c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | accuracy: 65.06600189208984% | Loss: 0.797803521156311\n",
            "Epoch: 2 | accuracy: 76.8219985961914% | Loss: 0.6793445348739624\n",
            "Epoch: 3 | accuracy: 80.697998046875% | Loss: 0.6568388938903809\n",
            "Epoch: 4 | accuracy: 82.4520034790039% | Loss: 0.6170578002929688\n",
            "Epoch: 5 | accuracy: 82.53199768066406% | Loss: 0.7501604557037354\n",
            "train_dataloader | accuracy: 82.6500015258789% \n"
          ]
        }
      ],
      "source": [
        "# TODO: Fill in the code cell according to the pytorch tutorial we gave.\n",
        "LR=0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "input_shape = (-1,3,32,32)\n",
        "for epoch in range(5):\n",
        "  model.train()\n",
        "  correct_train = 0\n",
        "  total_train = 0\n",
        "  for step, (x, y) in enumerate(train_dataloader):\n",
        "    b_x = Variable(x, requires_grad=False)\n",
        "    b_y = Variable(y, requires_grad=False)\n",
        "    out = model(b_x)\n",
        "    loss = loss_func(out, b_y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    predicted = torch.max(out.data, 1)[1]\n",
        "    total_train += len(b_y)\n",
        "    correct_train += (predicted == b_y).float().sum()\n",
        "  train_accuracy = 100 * correct_train / float(total_train)\n",
        "  print('Epoch: {} | accuracy: {}% | Loss: {}'.format(epoch + 1, train_accuracy, loss))\n",
        "\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "for step, (x, y) in enumerate(valid_dataloader):\n",
        "    b_x = Variable(x, requires_grad=False)\n",
        "    b_y = Variable(y, requires_grad=False)\n",
        "    out = model(b_x)\n",
        "    loss = loss_func(out, b_y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    predicted = torch.max(out.data, 1)[1]\n",
        "    total_test += len(b_y)\n",
        "    correct_test += (predicted == b_y).float().sum()\n",
        "test_accuracy = 100 * correct_test / float(total_test)\n",
        "print('train_dataloader | accuracy: {}% '.format(test_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqBGAUm6b5W"
      },
      "source": [
        "## Codes for Problem 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5SBFMzPT6cP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9a8c5c-0240-4df0-ec98-7e7ca7a8b558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | accuracy: 43.27799987792969% | Loss: 1.1996657848358154\n",
            "Epoch: 2 | accuracy: 57.70000076293945% | Loss: 1.036866307258606\n",
            "Epoch: 3 | accuracy: 63.104000091552734% | Loss: 1.058481216430664\n",
            "Epoch: 4 | accuracy: 66.60600280761719% | Loss: 0.9383122324943542\n",
            "Epoch: 5 | accuracy: 69.93800354003906% | Loss: 1.035589575767517\n",
            "Epoch: 6 | accuracy: 71.94000244140625% | Loss: 0.7491894960403442\n",
            "Epoch: 7 | accuracy: 73.5479965209961% | Loss: 0.8618677854537964\n",
            "Epoch: 8 | accuracy: 75.20999908447266% | Loss: 0.7155677080154419\n",
            "Epoch: 9 | accuracy: 76.2040023803711% | Loss: 0.44183674454689026\n",
            "Epoch: 10 | accuracy: 77.4260025024414% | Loss: 0.435247004032135\n",
            "train_dataloader | accuracy: 77.27999877929688% \n"
          ]
        }
      ],
      "source": [
        "# TODO: Try to achieve the best performance given all training data using whatever model and training strategy.\n",
        "# (New) (You cannot use the model that was pretrained on CIFAR10)\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
        "num_fc = model.fc.in_features\n",
        "model.fc = nn.Linear(num_fc, 10)\n",
        "# TODO: Fill in the code cell according to the pytorch tutorial we gave.\n",
        "LR=0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "input_shape = (-1,3,32,32)\n",
        "for epoch in range(10):\n",
        "  model.train()\n",
        "  correct_train = 0\n",
        "  total_train = 0\n",
        "  for step, (x, y) in enumerate(train_dataloader):\n",
        "    b_x = Variable(x, requires_grad=False)\n",
        "    b_y = Variable(y, requires_grad=False)\n",
        "    out = model(b_x)\n",
        "    loss = loss_func(out, b_y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    predicted = torch.max(out.data, 1)[1]\n",
        "    total_train += len(b_y)\n",
        "    correct_train += (predicted == b_y).float().sum()\n",
        "  train_accuracy = 100 * correct_train / float(total_train)\n",
        "  print('Epoch: {} | accuracy: {}% | Loss: {}'.format(epoch + 1, train_accuracy, loss))\n",
        "\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "for step, (x, y) in enumerate(valid_dataloader):\n",
        "    b_x = Variable(x, requires_grad=False)\n",
        "    b_y = Variable(y, requires_grad=False)\n",
        "    out = model(b_x)\n",
        "    loss = loss_func(out, b_y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    predicted = torch.max(out.data, 1)[1]\n",
        "    total_test += len(b_y)\n",
        "    correct_test += (predicted == b_y).float().sum()\n",
        "test_accuracy = 100 * correct_test / float(total_test)\n",
        "print('train_dataloader | accuracy: {}% '.format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSafuelpRYJ"
      },
      "source": [
        "## Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZctBdkurpQS"
      },
      "source": [
        "1. (30%) Finish the rest of the codes for Problem 1 and Problem 2 according to the hint. (2 code cells in total.)\n",
        "2. Train small model (resnet18) and big model (resnet50) from scratch on `sixteenth_train_dataloader`, `half_train_dataloader`, and `train_dataloader` respectively.\n",
        "3. (30%) Achieve the best performance given all training data using whatever model and training strategy.  \n",
        "  (You cannot use the model that was pretrained on CIFAR10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "786fQTdk0msC"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsd2yTmB0k5t"
      },
      "source": [
        "Write down your insights in the report. The file name should be report.pdf.\n",
        "For the following discussion, please present the results graphically as shown in Fig. 1 and discuss them.\n",
        "\n",
        "- (30%) The relationship between the accuracy, model size, and the training dataset size.  \n",
        "    (Total 6 models. Small model trains on the sixteenth, half, and all data. Big model trains on the sixteenth, half, and all data. If the result is different from Fig.1, please explain the possible reasons.)\n",
        "- (10%) What if we train the ResNet with ImageNet initialized weights (`weights=\"IMAGENET1K_V1\"`).\n",
        "Please explain why the relationship changed this way?\n",
        "\n",
        "Hint: You can try different hyperparameters combinations when training the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDxF-xIueMM"
      },
      "source": [
        "## Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sXpmSj2ufkh"
      },
      "source": [
        "1. [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MemcOLK_4ULJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}